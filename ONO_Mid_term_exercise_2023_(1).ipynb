{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AviWilbur/ML_Predict_NBA_Rookie/blob/main/ONO_Mid_term_exercise_2023_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxEMakEiBTl-"
      },
      "source": [
        "#Mid-term exercise - Avi Wilbur\n",
        "predicting whether rookie NBA players will remain in the NBA for more than five years based on various features. The dataset is preprocessed using techniques such as handling missing values, scaling features, and balancing the classes to ensure accurate predictions. Machine learning models, including Random Forest and Gradient Boosting classifiers, are employed to train and evaluate the predictive performance using metrics like accuracy, precision, and recall. The project also involves data visualization to understand the distribution of the target variable.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63MGm65eCjRr"
      },
      "source": [
        "#1. Load your libraries here:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ug3u-V4-BWTi"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.impute import KNNImputer\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zoS_ee5wDJDE"
      },
      "source": [
        "#Upload your data file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "_g0XLs7MDKQE",
        "outputId": "a9fcfa9a-060f-425a-eb50-303f93757207"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-eaed0a7d-2cf3-46db-b2a6-0842851ee2fa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-eaed0a7d-2cf3-46db-b2a6-0842851ee2fa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving nba_logreg.csv to nba_logreg (2).csv\n"
          ]
        }
      ],
      "source": [
        "# predict if rookie NBA will be in the NBA for more than 5 years\n",
        "from google.colab import files\n",
        "file = files.upload()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mO-FSmz3DTAj"
      },
      "source": [
        "#2. Read the file into a pandas data frame:\n",
        "Split your data to:\n",
        "\n",
        "X: the feature matrix\n",
        "\n",
        "y: the label vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-ydbL4lDXIa"
      },
      "outputs": [],
      "source": [
        "\n",
        "dataset_path ='nba_logreg.csv'\n",
        "\n",
        "data = pd.read_csv(dataset_path)\n",
        "\n",
        "target_column = 'TARGET_5Yrs'\n",
        "names_column = 'Name'\n",
        "\n",
        "X = data.drop(columns=[names_column,target_column])\n",
        "y = data[target_column]\n",
        "z = data[names_column]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0pX_Z0sJ5XB"
      },
      "source": [
        "#3. A. create and print a plot that demonstartes the frequency of each class of the label variable (Y). In addition, print the count of each of the classes  of the label variable (Y)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "KUXEeWIjKf_V",
        "outputId": "18761aa2-5033-4571-9c4e-933653c9645e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArcAAAIjCAYAAAAZajMiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABIyklEQVR4nO3de1xUdf7H8feAgtwGvHErL2iWYroWluKlmyQqukvSlkZJavZbF0vF+663tMIssywvXcU2XVdLrXTFFC0rSVPTzFtWGpoCGsF4SVA4vz98MOsEKIzI4On1fDzm8WjO+Z5zPt9hOL398p3vWAzDMAQAAACYgJurCwAAAAAqC+EWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWgCkcOHBAXbt2lb+/vywWi1asWOHqkhw8+uij8vX1rZJrffLJJ7JYLPrkk0+q5Hrlddddd+muu+5ydRmlOnTokCwWi1544YVKO2d1/DlcSU0VeQ9bLBZNnjy5wtcAKgPhFqiglJQUWSyWUh9jx451dXl/WAkJCdq1a5eeeeYZ/etf/1Lbtm1LbVccYsp6TJs2rYorr5jly5ere/fuqlevnjw8PBQaGqoHHnhA69evd3VpVa74d3Hr1q2uLsVpf/7zn+Xt7a2TJ0+W2SY+Pl4eHh765ZdfqrAy4NpVw9UFANeqKVOmKCwszGHbzTff7KJq/th+++03paen65///KeGDBlSrmP69u2rHj16lNh+yy23VHZ5lcIwDA0YMEApKSm65ZZblJSUpODgYB07dkzLly9Xly5d9MUXX6hDhw6uLrVMH3/8satLqHbi4+P10Ucfafny5erXr1+J/WfOnNEHH3ygbt26qW7duld8vTvuuEO//fabPDw8rvhcQHVFuAWc1L179zJHB3/v7Nmz8vDwkJsbfyy5Go4fPy5JCggIKPcxt956qx5++OGrVFHlmzFjhlJSUjRs2DC9+OKLslgs9n3//Oc/9a9//Us1alTvWzqBqqQ///nP8vPz06JFi0oNtx988IFOnz6t+Pj4K7rOxfegWrVqXdG5gOqO/9MClax4TtvixYs1fvx4XXfddfL29pbNZpMkbd68Wd26dZO/v7+8vb1155136osvvihxns8//1y33XabatWqpaZNm+q1117T5MmTHUJN8Z/YU1JSShxf2py3n3/+WQMGDFBQUJA8PT3VsmVLvf3226XWv2TJEj3zzDO6/vrrVatWLXXp0kXff/99iets3rxZPXr0UO3ateXj46PWrVvr5ZdfliTNnz9fFotFX3/9dYnjnn32Wbm7u+vnn3++5Ov59ddfq3v37rJarfL19VWXLl305Zdf2vdPnjxZjRo1kiSNGjVKFotFjRs3vuQ5y+uDDz5QTEyMQkND5enpqaZNm2rq1KkqLCws0fZSr8PFfv75Z8XGxsrX11f169fXyJEjSz3fxX777TclJyerefPmeuGFFxzeA8UeeeQR3X777WWe47PPPtNf//pXNWzYUJ6enmrQoIGGDx+u3377zaFdZmam+vfvr+uvv16enp4KCQnRX/7yFx06dMjeZuvWrYqOjla9evXk5eWlsLAwDRgw4JJ9kErOua3oe80ZBQUFmjhxoiIiIuTv7y8fHx917txZGzZsKPOYmTNnqlGjRvLy8tKdd96pb7/9tkSbffv26f7771edOnVUq1YttW3bVh9++GGF6/Py8lLv3r2Vlpam7OzsEvsXLVokPz8//fnPf1ZOTo5GjhypVq1aydfXV1arVd27d9fOnTsdjrnUPai0ObflfW8U+/HHHxUdHS0fHx+FhoZqypQpMgzjsn0tz/0HqAzV+5/5QDWWl5enEydOOGyrV6+e/b+nTp0qDw8PjRw5Uvn5+fLw8ND69evVvXt3RUREaNKkSXJzc9P8+fN1zz336LPPPrOHk127dqlr166qX7++Jk+erPPnz2vSpEkKCgpyut6srCy1b99eFotFQ4YMUf369bV69WoNHDhQNptNw4YNc2g/bdo0ubm5aeTIkcrLy9P06dMVHx+vzZs329usXbtWPXv2VEhIiIYOHarg4GDt3btXK1eu1NChQ3X//fcrMTFRCxcuLPHn/oULF+quu+7SddddV2bNu3fvVufOnWW1WjV69GjVrFlTr732mu666y59+umnateunXr37q2AgAANHz7cPtWgPB96OXPmTImfn3Rh9Ld4BDQlJUW+vr5KSkqSr6+v1q9fr4kTJ8pms+n5558v9+tQrLCwUNHR0WrXrp1eeOEFrVu3TjNmzFDTpk01ePDgMmv9/PPPlZOTo2HDhsnd3f2yfSvN0qVLdebMGQ0ePFh169bVli1b9Morr+jIkSNaunSpvV1cXJx2796tJ554Qo0bN1Z2drbWrl2rjIwM+/Pi9+bYsWMVEBCgQ4cOadmyZU7VJZXvveYsm82mN998U3379tWgQYN08uRJvfXWW4qOjtaWLVvUpk0bh/bvvPOOTp48qcTERJ09e1Yvv/yy7rnnHu3atcv++7d792517NhR1113ncaOHSsfHx8tWbJEsbGxev/993XfffdVqMb4+HgtWLBAS5YscZhWk5OTozVr1qhv377y8vLS7t27tWLFCv31r39VWFiYsrKy9Nprr+nOO+/Unj17FBoa6nDe0u5BpSnve0O68B7u1q2b2rdvr+nTpys1NVWTJk3S+fPnNWXKlDL7WNH7D3BFDAAVMn/+fENSqQ/DMIwNGzYYkowmTZoYZ86csR9XVFRkNGvWzIiOjjaKiors28+cOWOEhYUZ9957r31bbGysUatWLeOnn36yb9uzZ4/h7u5uXPxre/DgQUOSMX/+/BJ1SjImTZpkfz5w4EAjJCTEOHHihEO7Pn36GP7+/vZai+tv0aKFkZ+fb2/38ssvG5KMXbt2GYZhGOfPnzfCwsKMRo0aGb/++qvDOS/uX9++fY3Q0FCjsLDQvm379u1l1n2x2NhYw8PDw/jhhx/s244ePWr4+fkZd9xxR4nX4fnnn7/k+S5uW9YjPT3d3vbin1+x//u//zO8vb2Ns2fPVuh1SEhIMCQZU6ZMcWhzyy23GBEREZesufi1X758+WX7Zxj/+xlu2LDhkn1JTk42LBaL/X3266+/XvZ1XL58uSHJ+Oqrr8pVy8XuvPNO48477yxR5+Xea2Up/l28VC3nz593OLdhXOhnUFCQMWDAAPu24veFl5eXceTIEfv2zZs3G5KM4cOH27d16dLFaNWqlf09YBgXftYdOnQwmjVrVqJ/F/8cyqoxJCTEiIyMdNg+b948Q5KxZs0awzAM4+zZsw6/R8V1e3p6OryvyroHlVVTed4bhvG/9/ATTzzh0O+YmBjDw8PDOH78uH27s/cfoDIwLQFw0uzZs7V27VqHx8USEhLk5eVlf75jxw4dOHBADz30kH755RedOHFCJ06c0OnTp9WlSxdt3LhRRUVFKiws1Jo1axQbG6uGDRvaj2/RooWio6OdqtUwDL3//vvq1auXDMOwX/vEiROKjo5WXl6etm/f7nBM//79HUZ6OnfuLOnCnySlC9MFDh48qGHDhpWY63rxn8379euno0ePOvwZeOHChfLy8lJcXFyZNRcWFurjjz9WbGysmjRpYt8eEhKihx56SJ9//rl9qoczHn/88RI/v7Vr1yo8PNze5uKf38mTJ3XixAl17txZZ86c0b59+yr0OhT729/+5vC8c+fO9te0LMX99PPzq1AfL3ZxX06fPq0TJ06oQ4cOMgzDPm3Ey8tLHh4e+uSTT/Trr7+Wep7iPq5cuVLnzp1zup6LXe69diXc3d3t5y4qKlJOTo7Onz+vtm3blnjPS1JsbKzDXxNuv/12tWvXTv/9738lXRhNXb9+vR544AH7e+LEiRP65ZdfFB0drQMHDlx2qk1pNfbp00fp6ekO0z8WLVqkoKAgdenSRZLk6elpn7dfWFioX375Rb6+vrrppptK7cvv70FlKc9742IXjy4Xj8QWFBRo3bp1pZ7fmfsPcCWYlgA46fbbb7/kB8p+v5LCgQMHJF34H05Z8vLylJ+fr99++03NmjUrsf+mm26y/0+2Io4fP67c3Fy9/vrrev3110tt8/v5fhcHa0mqXbu2JNlDzw8//CDp8itE3HvvvQoJCdHChQvVpUsXFRUV6d///rf+8pe/XDKsHT9+XGfOnNFNN91UYl+LFi1UVFSkw4cPq2XLlpe8flmaNWumqKioS7bZvXu3xo8fr/Xr15cI0nl5eZLK/zpIUq1atVS/fn2HbbVr1y4zSBazWq2SdMnloi4nIyNDEydO1IcffljiesV98fT01HPPPacRI0YoKChI7du3V8+ePdWvXz8FBwdLku68807FxcXpqaee0syZM3XXXXcpNjZWDz30kDw9PZ2q7XLvtSu1YMECzZgxQ/v27XMI5L//HZVU6u/djTfeqCVLlkiSvv/+exmGoQkTJmjChAmlXi87O/uS021KEx8fr5kzZ2rRokX6xz/+oSNHjuizzz7Tk08+aZ+KUlRUpJdffllz5szRwYMHHeZql7aSQmn9K0153hvF3NzcHP6xKV14fSQ5BPOLOXP/Aa4E4Ra4Sn4/YlJUVCRJev7550vM8yvm6+ur/Pz8cl+jtJFBSSU+oFR87YcffrjMcN26dWuH52XN7TTK8cGR35/noYce0htvvKE5c+boiy++0NGjR6v9SgW5ubm68847ZbVaNWXKFDVt2lS1atXS9u3bNWbMGPtrWhHOzpdt3ry5pAtzsWNjYyt8fGFhoe69917l5ORozJgxat68uXx8fPTzzz/r0UcfdejLsGHD1KtXL61YsUJr1qzRhAkTlJycrPXr1+uWW26RxWLRe++9py+//FIfffSR1qxZowEDBmjGjBn68ssvnfqiisp6r5Xm3Xff1aOPPqrY2FiNGjVKgYGBcnd3V3Jysv0fJhVR/FqNHDmyzL+k3HDDDRU+b0REhJo3b65///vf+sc//qF///vfMgzDYZWEZ599VhMmTNCAAQM0depU1alTR25ubho2bFip78fyjNpW5L3hLGfuP8CVINwCVaRp06aSLozCXWrEsH79+vLy8rKP9F5s//79Ds+LR7hyc3Mdtv/0008lzunn56fCwsLLjlaWV3F/vv3228ues1+/fpoxY4Y++ugjrV69WvXr17/sFIv69evL29u7RJ+lC59Ud3NzU4MGDZzvwGV88skn+uWXX7Rs2TLdcccd9u0HDx50aFeR18FZnTp1Uu3ate3Bp6IhedeuXfruu++0YMECh+Wmfj+VpljTpk01YsQIjRgxQgcOHFCbNm00Y8YMvfvuu/Y27du3V/v27fXMM89o0aJFio+P1+LFi/XYY48518mr5L333lOTJk20bNkyh38MTpo0qdT2pf3efffdd/YVOIpHLWvWrFnpP+/4+HhNmDBB33zzjRYtWqRmzZrptttus+9/7733dPfdd+utt95yOC43N9fhw6wVUdH3RlFRkX788Uf7aK104fWRVOYqJVfj/gNcCnNugSoSERGhpk2b6oUXXtCpU6dK7C9eq9Xd3V3R0dFasWKFMjIy7Pv37t2rNWvWOBxjtVpVr149bdy40WH7nDlzHJ67u7srLi5O77//fqnLGhVfuyJuvfVWhYWF6aWXXioRrn8/4ta6dWu1bt1ab775pt5//3316dPnsmuyuru7q2vXrvrggw8c/tyZlZWlRYsWqVOnTvY/118NxQHy4r4UFBSUeG0r8jo4y9vbW2PGjNHevXs1ZsyYUs/77rvvasuWLaUeX1pfDMMosVTZmTNndPbsWYdtTZs2lZ+fn/0vCr/++muJ6xf/JaIif3WoKqX1ffPmzUpPTy+1/YoVKxzmzG7ZskWbN29W9+7dJUmBgYG666679Nprr+nYsWMljnfmd6lY8SjtxIkTtWPHjhJr27q7u5d47ZcuXVrhOb6/P6d0+ffGxV599VWHtq+++qpq1qxpnxtc2jUq+/4DXAojt0AVcXNz05tvvqnu3burZcuW6t+/v6677jr9/PPP2rBhg6xWqz766CNJ0lNPPaXU1FR17txZf//733X+/Hm98soratmypb755huH8z722GOaNm2aHnvsMbVt21YbN260j6RcbNq0adqwYYPatWunQYMGKTw8XDk5Odq+fbvWrVunnJycCvdn7ty56tWrl9q0aaP+/fsrJCRE+/bt0+7du0sE8X79+mnkyJGSVO4pCU8//bTWrl2rTp066e9//7tq1Kih1157Tfn5+Zo+fXqF6v297du3O4xEFmvatKkiIyPVoUMH1a5dWwkJCXryySdlsVj0r3/9q0S4qOjr4KxRo0Zp9+7dmjFjhjZs2KD7779fwcHByszM1IoVK7RlyxZt2rSp1GObN2+upk2bauTIkfr5559ltVr1/vvvl5hf+d1336lLly564IEHFB4erho1amj58uXKyspSnz59JF2Yvzpnzhzdd999atq0qU6ePKk33nhDVqu11G98qwpvv/22UlNTS2wfOnSoevbsqWXLlum+++5TTEyMDh48qHnz5ik8PLzUf2TecMMN6tSpkwYPHqz8/Hy99NJLqlu3rkaPHm1vM3v2bHXq1EmtWrXSoEGD1KRJE2VlZSk9PV1Hjhwpse5seYWFhalDhw764IMPJKlEuO3Zs6emTJmi/v37q0OHDtq1a5cWLlxYYg5sRZT3vVGsVq1aSk1NVUJCgtq1a6fVq1dr1apV+sc//lFiPvnFKvv+A1xSFa7MAJjC5ZYfKl5qZ+nSpaXu//rrr43evXsbdevWNTw9PY1GjRoZDzzwgJGWlubQ7tNPPzUiIiIMDw8Po0mTJsa8efOMSZMmGb//tT1z5owxcOBAw9/f3/Dz8zMeeOABIzs7u8RSPIZhGFlZWUZiYqLRoEEDo2bNmkZwcLDRpUsX4/XXX79s/WUtO/b5558b9957r+Hn52f4+PgYrVu3Nl555ZUS/T527Jjh7u5u3HjjjaW+LmXZvn27ER0dbfj6+hre3t7G3XffbWzatKnU2ipjKbCEhAR72y+++MJo37694eXlZYSGhhqjR4821qxZU+ryTpd7HRISEgwfH58S9ZT2M72U9957z+jatatRp04do0aNGkZISIjx4IMPGp988om9TWnLPe3Zs8eIiooyfH19jXr16hmDBg0ydu7c6fAzPXHihJGYmGg0b97c8PHxMfz9/Y127doZS5YssZ9n+/btRt++fY2GDRsanp6eRmBgoNGzZ09j69atl629rKXAyvte+71LLcsnyTh8+LBRVFRkPPvss0ajRo0MT09P45ZbbjFWrlxpJCQkGI0aNSpxzeeff96YMWOG0aBBA8PT09Po3LmzsXPnzhLX/uGHH4x+/foZwcHBRs2aNY3rrrvO6Nmzp/Hee+9d8udwObNnzzYkGbfffnuJfWfPnjVGjBhhhISEGF5eXkbHjh2N9PT0cr+uZdVUnveGYfzvPfzDDz8YXbt2Nby9vY2goCBj0qRJJZYoc/b+A1QGi2FU0t/NAFx1kydP1lNPPVVpf+6uSidOnFBISIgmTpxY5qfMAQC4Usy5BVAlUlJSVFhYqEceecTVpQAATIw5twCuqvXr12vPnj165plnFBsbW+YnqgEAqAyEWwBX1ZQpU7Rp0yZ17NhRr7zyiqvLAQCYHHNuAQAAYBrMuQUAAIBpEG4BAABgGsy51YWvEzx69Kj8/Pwcvp4RAAAA1YNhGDp58qRCQ0Pl5lb2+CzhVtLRo0ev6nfUAwAAoHIcPnxY119/fZn7CbeS/Pz8JF14sa7md9UDAADAOTabTQ0aNLDntrIQbiX7VASr1Uq4BQAAqMYuN4WUD5QBAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyjhqsLwLWr8dhVri4BfxCHpsW4ugQAwDWCkVsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGm4NNwWFhZqwoQJCgsLk5eXl5o2baqpU6fKMAx7G8MwNHHiRIWEhMjLy0tRUVE6cOCAw3lycnIUHx8vq9WqgIAADRw4UKdOnarq7gAAAMDFXBpun3vuOc2dO1evvvqq9u7dq+eee07Tp0/XK6+8Ym8zffp0zZo1S/PmzdPmzZvl4+Oj6OhonT171t4mPj5eu3fv1tq1a7Vy5Upt3LhRjz/+uCu6BAAAABeyGBcPk1axnj17KigoSG+99ZZ9W1xcnLy8vPTuu+/KMAyFhoZqxIgRGjlypCQpLy9PQUFBSklJUZ8+fbR3716Fh4frq6++Utu2bSVJqamp6tGjh44cOaLQ0NDL1mGz2eTv76+8vDxZrdar01kTajx2latLwB/EoWkxri4BAOBi5c1rLh257dChg9LS0vTdd99Jknbu3KnPP/9c3bt3lyQdPHhQmZmZioqKsh/j7++vdu3aKT09XZKUnp6ugIAAe7CVpKioKLm5uWnz5s2lXjc/P182m83hAQAAgGtfDVdefOzYsbLZbGrevLnc3d1VWFioZ555RvHx8ZKkzMxMSVJQUJDDcUFBQfZ9mZmZCgwMdNhfo0YN1alTx97m95KTk/XUU09VdncAAADgYi4duV2yZIkWLlyoRYsWafv27VqwYIFeeOEFLViw4Kped9y4ccrLy7M/Dh8+fFWvBwAAgKrh0pHbUaNGaezYserTp48kqVWrVvrpp5+UnJyshIQEBQcHS5KysrIUEhJiPy4rK0tt2rSRJAUHBys7O9vhvOfPn1dOTo79+N/z9PSUp6fnVegRAAAAXMmlI7dnzpyRm5tjCe7u7ioqKpIkhYWFKTg4WGlpafb9NptNmzdvVmRkpCQpMjJSubm52rZtm73N+vXrVVRUpHbt2lVBLwAAAFBduHTktlevXnrmmWfUsGFDtWzZUl9//bVefPFFDRgwQJJksVg0bNgwPf3002rWrJnCwsI0YcIEhYaGKjY2VpLUokULdevWTYMGDdK8efN07tw5DRkyRH369CnXSgkAAAAwD5eG21deeUUTJkzQ3//+d2VnZys0NFT/93//p4kTJ9rbjB49WqdPn9bjjz+u3NxcderUSampqapVq5a9zcKFCzVkyBB16dJFbm5uiouL06xZs1zRJQAAALiQS9e5rS5Y59Y5rHOLqsI6twCAa2KdWwAAAKAyEW4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGi4Nt40bN5bFYinxSExMlCSdPXtWiYmJqlu3rnx9fRUXF6esrCyHc2RkZCgmJkbe3t4KDAzUqFGjdP78eVd0BwAAAC7m0nD71Vdf6dixY/bH2rVrJUl//etfJUnDhw/XRx99pKVLl+rTTz/V0aNH1bt3b/vxhYWFiomJUUFBgTZt2qQFCxYoJSVFEydOdEl/AAAA4FoWwzAMVxdRbNiwYVq5cqUOHDggm82m+vXra9GiRbr//vslSfv27VOLFi2Unp6u9u3ba/Xq1erZs6eOHj2qoKAgSdK8efM0ZswYHT9+XB4eHuW6rs1mk7+/v/Ly8mS1Wq9a/8ym8dhVri4BfxCHpsW4ugQAgIuVN69Vmzm3BQUFevfddzVgwABZLBZt27ZN586dU1RUlL1N8+bN1bBhQ6Wnp0uS0tPT1apVK3uwlaTo6GjZbDbt3r27zGvl5+fLZrM5PAAAAHDtqzbhdsWKFcrNzdWjjz4qScrMzJSHh4cCAgIc2gUFBSkzM9Pe5uJgW7y/eF9ZkpOT5e/vb380aNCg8joCAAAAl6k24fatt95S9+7dFRoaetWvNW7cOOXl5dkfhw8fvurXBAAAwNVXw9UFSNJPP/2kdevWadmyZfZtwcHBKigoUG5ursPobVZWloKDg+1ttmzZ4nCu4tUUituUxtPTU56enpXYAwAAAFQH1WLkdv78+QoMDFRMzP8+NBIREaGaNWsqLS3Nvm3//v3KyMhQZGSkJCkyMlK7du1Sdna2vc3atWtltVoVHh5edR0AAABAteDykduioiLNnz9fCQkJqlHjf+X4+/tr4MCBSkpKUp06dWS1WvXEE08oMjJS7du3lyR17dpV4eHheuSRRzR9+nRlZmZq/PjxSkxMZGQWAADgD8jl4XbdunXKyMjQgAEDSuybOXOm3NzcFBcXp/z8fEVHR2vOnDn2/e7u7lq5cqUGDx6syMhI+fj4KCEhQVOmTKnKLgAAAKCaqFbr3LoK69w6h3VuUVVY5xYAcM2tcwsAAABcKcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATMPl4fbnn3/Www8/rLp168rLy0utWrXS1q1b7fsNw9DEiRMVEhIiLy8vRUVF6cCBAw7nyMnJUXx8vKxWqwICAjRw4ECdOnWqqrsCAAAAF3NpuP3111/VsWNH1axZU6tXr9aePXs0Y8YM1a5d295m+vTpmjVrlubNm6fNmzfLx8dH0dHROnv2rL1NfHy8du/erbVr12rlypXauHGjHn/8cVd0CQAAAC5kMQzDcNXFx44dqy+++EKfffZZqfsNw1BoaKhGjBihkSNHSpLy8vIUFBSklJQU9enTR3v37lV4eLi++uortW3bVpKUmpqqHj166MiRIwoNDb1sHTabTf7+/srLy5PVaq28Dppc47GrXF0C/iAOTYtxdQkAABcrb15z6cjthx9+qLZt2+qvf/2rAgMDdcstt+iNN96w7z948KAyMzMVFRVl3+bv76927dopPT1dkpSenq6AgAB7sJWkqKgoubm5afPmzaVeNz8/XzabzeEBAACAa59Lw+2PP/6ouXPnqlmzZlqzZo0GDx6sJ598UgsWLJAkZWZmSpKCgoIcjgsKCrLvy8zMVGBgoMP+GjVqqE6dOvY2v5ecnCx/f3/7o0GDBpXdNQAAALiAS8NtUVGRbr31Vj377LO65ZZb9Pjjj2vQoEGaN2/eVb3uuHHjlJeXZ38cPnz4ql4PAAAAVcOl4TYkJETh4eEO21q0aKGMjAxJUnBwsCQpKyvLoU1WVpZ9X3BwsLKzsx32nz9/Xjk5OfY2v+fp6Smr1erwAAAAwLXPpeG2Y8eO2r9/v8O27777To0aNZIkhYWFKTg4WGlpafb9NptNmzdvVmRkpCQpMjJSubm52rZtm73N+vXrVVRUpHbt2lVBLwAAAFBd1HDlxYcPH64OHTro2Wef1QMPPKAtW7bo9ddf1+uvvy5JslgsGjZsmJ5++mk1a9ZMYWFhmjBhgkJDQxUbGyvpwkhvt27d7NMZzp07pyFDhqhPnz7lWikBAAAA5uHScHvbbbdp+fLlGjdunKZMmaKwsDC99NJLio+Pt7cZPXq0Tp8+rccff1y5ubnq1KmTUlNTVatWLXubhQsXasiQIerSpYvc3NwUFxenWbNmuaJLAAAAcCGXrnNbXbDOrXNY5xZVhXVuAQDXxDq3AAAAQGUi3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANOo4eoCAACoLhqPXeXqEvAHcWhajKtLMC2XjtxOnjxZFovF4dG8eXP7/rNnzyoxMVF169aVr6+v4uLilJWV5XCOjIwMxcTEyNvbW4GBgRo1apTOnz9f1V0BAABANeDykduWLVtq3bp19uc1avyvpOHDh2vVqlVaunSp/P39NWTIEPXu3VtffPGFJKmwsFAxMTEKDg7Wpk2bdOzYMfXr1081a9bUs88+W+V9AQAAgGu5PNzWqFFDwcHBJbbn5eXprbfe0qJFi3TPPfdIkubPn68WLVroyy+/VPv27fXxxx9rz549WrdunYKCgtSmTRtNnTpVY8aM0eTJk+Xh4VHV3QEAAIALufwDZQcOHFBoaKiaNGmi+Ph4ZWRkSJK2bdumc+fOKSoqyt62efPmatiwodLT0yVJ6enpatWqlYKCguxtoqOjZbPZtHv37jKvmZ+fL5vN5vAAAADAtc+l4bZdu3ZKSUlRamqq5s6dq4MHD6pz5846efKkMjMz5eHhoYCAAIdjgoKClJmZKUnKzMx0CLbF+4v3lSU5OVn+/v72R4MGDSq3YwAAAHAJp6Yl/Pjjj2rSpMkVX7x79+72/27durXatWunRo0aacmSJfLy8rri85dl3LhxSkpKsj+32WwEXAAAABNwauT2hhtu0N133613331XZ8+erbRiAgICdOONN+r7779XcHCwCgoKlJub69AmKyvLPkc3ODi4xOoJxc9Lm8dbzNPTU1ar1eEBAACAa59T4Xb79u1q3bq1kpKSFBwcrP/7v//Tli1brriYU6dO6YcfflBISIgiIiJUs2ZNpaWl2ffv379fGRkZioyMlCRFRkZq165dys7OtrdZu3atrFarwsPDr7geAAAAXFucCrdt2rTRyy+/rKNHj+rtt9/WsWPH1KlTJ91888168cUXdfz48XKdZ+TIkfr000916NAhbdq0Sffdd5/c3d3Vt29f+fv7a+DAgUpKStKGDRu0bds29e/fX5GRkWrfvr0kqWvXrgoPD9cjjzyinTt3as2aNRo/frwSExPl6enpTNcAAABwDbuiD5TVqFFDvXv31tKlS/Xcc8/p+++/18iRI9WgQQP169dPx44du+TxR44cUd++fXXTTTfpgQceUN26dfXll1+qfv36kqSZM2eqZ8+eiouL0x133KHg4GAtW7bMfry7u7tWrlwpd3d3RUZG6uGHH1a/fv00ZcqUK+kWAAAArlEWwzAMZw/eunWr3n77bS1evFg+Pj5KSEjQwIEDdeTIET311FOy2WyVMl3harPZbPL391deXh7zbyuAr6lEVeFrKlFVuK+hqnBfq7jy5jWnVkt48cUXNX/+fO3fv189evTQO++8ox49esjN7cJAcFhYmFJSUtS4cWOnigcAAACc4VS4nTt3rgYMGKBHH31UISEhpbYJDAzUW2+9dUXFAQAAABXhVLg9cODAZdt4eHgoISHBmdMDAAAATnHqA2Xz58/X0qVLS2xfunSpFixYcMVFAQAAAM5wKtwmJyerXr16JbYHBgbq2WefveKiAAAAAGc4FW4zMjIUFhZWYnujRo2UkZFxxUUBAAAAznAq3AYGBuqbb74psX3nzp2qW7fuFRcFAAAAOMOpcNu3b189+eST2rBhgwoLC1VYWKj169dr6NCh6tOnT2XXCAAAAJSLU6slTJ06VYcOHVKXLl1Uo8aFUxQVFalfv37MuQUAAIDLOBVuPTw89J///EdTp07Vzp075eXlpVatWqlRo0aVXR8AAABQbk6F22I33nijbrzxxsqqBQAAALgiToXbwsJCpaSkKC0tTdnZ2SoqKnLYv379+kopDgAAAKgIp8Lt0KFDlZKSopiYGN18882yWCyVXRcAAABQYU6F28WLF2vJkiXq0aNHZdcDAAAAOM2ppcA8PDx0ww03VHYtAAAAwBVxKtyOGDFCL7/8sgzDqOx6AAAAAKc5NS3h888/14YNG7R69Wq1bNlSNWvWdNi/bNmySikOAAAAqAinwm1AQIDuu+++yq4FAAAAuCJOhdv58+dXdh0AAADAFXNqzq0knT9/XuvWrdNrr72mkydPSpKOHj2qU6dOVVpxAAAAQEU4NXL7008/qVu3bsrIyFB+fr7uvfde+fn56bnnnlN+fr7mzZtX2XUCAAAAl+XUyO3QoUPVtm1b/frrr/Ly8rJvv++++5SWllZpxQEAAAAV4dTI7WeffaZNmzbJw8PDYXvjxo31888/V0phAAAAQEU5NXJbVFSkwsLCEtuPHDkiPz+/Ky4KAAAAcIZT4bZr16566aWX7M8tFotOnTqlSZMm8ZW8AAAAcBmnpiXMmDFD0dHRCg8P19mzZ/XQQw/pwIEDqlevnv79739Xdo0AAABAuTgVbq+//nrt3LlTixcv1jfffKNTp05p4MCBio+Pd/iAGQAAAFCVnAq3klSjRg09/PDDlVkLAAAAcEWcCrfvvPPOJff369fPqWIAAACAK+FUuB06dKjD83PnzunMmTPy8PCQt7c34RYAAAAu4dRqCb/++qvD49SpU9q/f786derEB8oAAADgMk6F29I0a9ZM06ZNKzGqCwAAAFSVSgu30oUPmR09erQyTwkAAACUm1Nzbj/88EOH54Zh6NixY3r11VfVsWPHSikMAAAAqCinwm1sbKzDc4vFovr16+uee+7RjBkzKqMuAAAAoMKcCrdFRUWVXQcAAABwxSp1zi0AAADgSk6N3CYlJZW77YsvvujMJQAAAIAKcyrcfv311/r666917tw53XTTTZKk7777Tu7u7rr11lvt7SwWS+VUCQAAAJSDU+G2V69e8vPz04IFC1S7dm1JF77YoX///urcubNGjBhRqUUCAAAA5eHUnNsZM2YoOTnZHmwlqXbt2nr66adZLQEAAAAu41S4tdlsOn78eIntx48f18mTJ6+4KAAAAMAZToXb++67T/3799eyZct05MgRHTlyRO+//74GDhyo3r17O1XItGnTZLFYNGzYMPu2s2fPKjExUXXr1pWvr6/i4uKUlZXlcFxGRoZiYmLk7e2twMBAjRo1SufPn3eqBgAAAFzbnJpzO2/ePI0cOVIPPfSQzp07d+FENWpo4MCBev755yt8vq+++kqvvfaaWrdu7bB9+PDhWrVqlZYuXSp/f38NGTJEvXv31hdffCFJKiwsVExMjIKDg7Vp0yYdO3ZM/fr1U82aNfXss8860zUAAABcw5waufX29tacOXP0yy+/2FdOyMnJ0Zw5c+Tj41Ohc506dUrx8fF64403HObw5uXl6a233tKLL76oe+65RxEREZo/f742bdqkL7/8UpL08ccfa8+ePXr33XfVpk0bde/eXVOnTtXs2bNVUFDgTNcAAABwDbuiL3E4duyYjh07pmbNmsnHx0eGYVT4HImJiYqJiVFUVJTD9m3btuncuXMO25s3b66GDRsqPT1dkpSenq5WrVopKCjI3iY6Olo2m027d+8u85r5+fmy2WwODwAAAFz7nAq3v/zyi7p06aIbb7xRPXr00LFjxyRJAwcOrNAyYIsXL9b27duVnJxcYl9mZqY8PDwUEBDgsD0oKEiZmZn2NhcH2+L9xfvKkpycLH9/f/ujQYMG5a4ZAAAA1ZdT4Xb48OGqWbOmMjIy5O3tbd/+4IMPKjU1tVznOHz4sIYOHaqFCxeqVq1azpThtHHjxikvL8/+OHz4cJVeHwAAAFeHUx8o+/jjj7VmzRpdf/31DtubNWumn376qVzn2LZtm7Kzsx2+0aywsFAbN27Uq6++qjVr1qigoEC5ubkOo7dZWVkKDg6WJAUHB2vLli0O5y1eTaG4TWk8PT3l6elZrjoBAABw7XBq5Pb06dMOI7bFcnJyyh0au3Tpol27dmnHjh32R9u2bRUfH2//75o1ayotLc1+zP79+5WRkaHIyEhJUmRkpHbt2qXs7Gx7m7Vr18pqtSo8PNyZrgEAAOAa5tTIbefOnfXOO+9o6tSpkiSLxaKioiJNnz5dd999d7nO4efnp5tvvtlhm4+Pj+rWrWvfPnDgQCUlJalOnTqyWq164oknFBkZqfbt20uSunbtqvDwcD3yyCOaPn26MjMzNX78eCUmJjIyCwAA8AfkVLidPn26unTpoq1bt6qgoECjR4/W7t27lZOTY1+DtjLMnDlTbm5uiouLU35+vqKjozVnzhz7fnd3d61cuVKDBw9WZGSkfHx8lJCQoClTplRaDQAAALh2WAxn1u/ShXVoX331Ve3cuVOnTp3SrbfeqsTERIWEhFR2jVedzWaTv7+/8vLyZLVaXV3ONaPx2FWuLgF/EIemxbi6BPxBcF9DVeG+VnHlzWsVHrk9d+6cunXrpnnz5umf//znFRUJAAAAVKYKf6CsZs2a+uabb65GLQAAAMAVcWq1hIcfflhvvfVWZdcCAAAAXBGnPlB2/vx5vf3221q3bp0iIiLk4+PjsP/FF1+slOIAAACAiqhQuP3xxx/VuHFjffvtt/YvX/juu+8c2lgslsqrDgAAAKiACoXbZs2a6dixY9qwYYOkC1+3O2vWLAUFBV2V4gAAAICKqNCc29+vGrZ69WqdPn26UgsCAAAAnOXUB8qKOblELgAAAHBVVCjcWiyWEnNqmWMLAACA6qJCc24Nw9Cjjz4qT09PSdLZs2f1t7/9rcRqCcuWLau8CgEAAIByqlC4TUhIcHj+8MMPV2oxAAAAwJWoULidP3/+1aoDAAAAuGJX9IEyAAAAoDoh3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0CLcAAAAwDcItAAAATINwCwAAANMg3AIAAMA0XBpu586dq9atW8tqtcpqtSoyMlKrV6+27z979qwSExNVt25d+fr6Ki4uTllZWQ7nyMjIUExMjLy9vRUYGKhRo0bp/PnzVd0VAAAAVAMuDbfXX3+9pk2bpm3btmnr1q2655579Je//EW7d++WJA0fPlwfffSRli5dqk8//VRHjx5V79697ccXFhYqJiZGBQUF2rRpkxYsWKCUlBRNnDjRVV0CAACAC1kMwzBcXcTF6tSpo+eff17333+/6tevr0WLFun++++XJO3bt08tWrRQenq62rdvr9WrV6tnz546evSogoKCJEnz5s3TmDFjdPz4cXl4eJTrmjabTf7+/srLy5PVar1qfTObxmNXuboE/EEcmhbj6hLwB8F9DVWF+1rFlTevVZs5t4WFhVq8eLFOnz6tyMhIbdu2TefOnVNUVJS9TfPmzdWwYUOlp6dLktLT09WqVSt7sJWk6Oho2Ww2++hvafLz82Wz2RweAAAAuPa5PNzu2rVLvr6+8vT01N/+9jctX75c4eHhyszMlIeHhwICAhzaBwUFKTMzU5KUmZnpEGyL9xfvK0tycrL8/f3tjwYNGlRupwAAAOASLg+3N910k3bs2KHNmzdr8ODBSkhI0J49e67qNceNG6e8vDz74/Dhw1f1egAAAKgaNVxdgIeHh2644QZJUkREhL766iu9/PLLevDBB1VQUKDc3FyH0dusrCwFBwdLkoKDg7VlyxaH8xWvplDcpjSenp7y9PSs5J4AAADA1Vw+cvt7RUVFys/PV0REhGrWrKm0tDT7vv379ysjI0ORkZGSpMjISO3atUvZ2dn2NmvXrpXValV4eHiV1w4AAADXcunI7bhx49S9e3c1bNhQJ0+e1KJFi/TJJ59ozZo18vf318CBA5WUlKQ6derIarXqiSeeUGRkpNq3by9J6tq1q8LDw/XII49o+vTpyszM1Pjx45WYmMjILAAAwB+QS8Ntdna2+vXrp2PHjsnf31+tW7fWmjVrdO+990qSZs6cKTc3N8XFxSk/P1/R0dGaM2eO/Xh3d3etXLlSgwcPVmRkpHx8fJSQkKApU6a4qksAAABwoWq3zq0rsM6tc1gPElWF9SBRVbivoapwX6u4a26dWwAAAOBKEW4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGoRbAAAAmAbhFgAAAKZBuAUAAIBpEG4BAABgGi4Nt8nJybrtttvk5+enwMBAxcbGav/+/Q5tzp49q8TERNWtW1e+vr6Ki4tTVlaWQ5uMjAzFxMTI29tbgYGBGjVqlM6fP1+VXQEAAEA14NJw++mnnyoxMVFffvml1q5dq3Pnzqlr1646ffq0vc3w4cP10UcfaenSpfr000919OhR9e7d276/sLBQMTExKigo0KZNm7RgwQKlpKRo4sSJrugSAAAAXMhiGIbh6iKKHT9+XIGBgfr00091xx13KC8vT/Xr19eiRYt0//33S5L27dunFi1aKD09Xe3bt9fq1avVs2dPHT16VEFBQZKkefPmacyYMTp+/Lg8PDwue12bzSZ/f3/l5eXJarVe1T6aSeOxq1xdAv4gDk2LcXUJ+IPgvoaqwn2t4sqb16rVnNu8vDxJUp06dSRJ27Zt07lz5xQVFWVv07x5czVs2FDp6emSpPT0dLVq1coebCUpOjpaNptNu3fvLvU6+fn5stlsDg8AAABc+6pNuC0qKtKwYcPUsWNH3XzzzZKkzMxMeXh4KCAgwKFtUFCQMjMz7W0uDrbF+4v3lSY5OVn+/v72R4MGDSq5NwAAAHCFahNuExMT9e2332rx4sVX/Vrjxo1TXl6e/XH48OGrfk0AAABcfTVcXYAkDRkyRCtXrtTGjRt1/fXX27cHBweroKBAubm5DqO3WVlZCg4OtrfZsmWLw/mKV1MobvN7np6e8vT0rOReAAAAwNVcOnJrGIaGDBmi5cuXa/369QoLC3PYHxERoZo1ayotLc2+bf/+/crIyFBkZKQkKTIyUrt27VJ2dra9zdq1a2W1WhUeHl41HQEAAEC14NKR28TERC1atEgffPCB/Pz87HNk/f395eXlJX9/fw0cOFBJSUmqU6eOrFarnnjiCUVGRqp9+/aSpK5duyo8PFyPPPKIpk+frszMTI0fP16JiYmMzgIAAPzBuDTczp07V5J01113OWyfP3++Hn30UUnSzJkz5ebmpri4OOXn5ys6Olpz5syxt3V3d9fKlSs1ePBgRUZGysfHRwkJCZoyZUpVdQMAAADVhEvDbXmW2K1Vq5Zmz56t2bNnl9mmUaNG+u9//1uZpQEAAOAaVG1WSwAAAACuFOEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApuHScLtx40b16tVLoaGhslgsWrFihcN+wzA0ceJEhYSEyMvLS1FRUTpw4IBDm5ycHMXHx8tqtSogIEADBw7UqVOnqrAXAAAAqC5cGm5Pnz6tP/3pT5o9e3ap+6dPn65Zs2Zp3rx52rx5s3x8fBQdHa2zZ8/a28THx2v37t1au3atVq5cqY0bN+rxxx+vqi4AAACgGqnhyot3795d3bt3L3WfYRh66aWXNH78eP3lL3+RJL3zzjsKCgrSihUr1KdPH+3du1epqan66quv1LZtW0nSK6+8oh49euiFF15QaGholfUFAAAArldt59wePHhQmZmZioqKsm/z9/dXu3btlJ6eLklKT09XQECAPdhKUlRUlNzc3LR58+Yyz52fny+bzebwAAAAwLWv2obbzMxMSVJQUJDD9qCgIPu+zMxMBQYGOuyvUaOG6tSpY29TmuTkZPn7+9sfDRo0qOTqAQAA4ArVNtxeTePGjVNeXp79cfjwYVeXBAAAgEpQbcNtcHCwJCkrK8the1ZWln1fcHCwsrOzHfafP39eOTk59jal8fT0lNVqdXgAAADg2ldtw21YWJiCg4OVlpZm32az2bR582ZFRkZKkiIjI5Wbm6tt27bZ26xfv15FRUVq165dldcMAAAA13LpagmnTp3S999/b39+8OBB7dixQ3Xq1FHDhg01bNgwPf3002rWrJnCwsI0YcIEhYaGKjY2VpLUokULdevWTYMGDdK8efN07tw5DRkyRH369GGlBAAAgD8gl4bbrVu36u6777Y/T0pKkiQlJCQoJSVFo0eP1unTp/X4448rNzdXnTp1UmpqqmrVqmU/ZuHChRoyZIi6dOkiNzc3xcXFadasWVXeFwAAALiexTAMw9VFuJrNZpO/v7/y8vKYf1sBjceucnUJ+IM4NC3G1SXgD4L7GqoK97WKK29eq7ZzbgEAAICKItwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANEwTbmfPnq3GjRurVq1aateunbZs2eLqkgAAAFDFTBFu//Of/ygpKUmTJk3S9u3b9ac//UnR0dHKzs52dWkAAACoQqYIty+++KIGDRqk/v37Kzw8XPPmzZO3t7fefvttV5cGAACAKlTD1QVcqYKCAm3btk3jxo2zb3Nzc1NUVJTS09NLPSY/P1/5+fn253l5eZIkm812dYs1maL8M64uAX8Q/G6iqnBfQ1XhvlZxxa+ZYRiXbHfNh9sTJ06osLBQQUFBDtuDgoK0b9++Uo9JTk7WU089VWJ7gwYNrkqNAK6M/0uurgAAKhf3NeedPHlS/v7+Ze6/5sOtM8aNG6ekpCT786KiIuXk5Khu3bqyWCwurAxmZ7PZ1KBBAx0+fFhWq9XV5QDAFeO+hqpiGIZOnjyp0NDQS7a75sNtvXr15O7urqysLIftWVlZCg4OLvUYT09PeXp6OmwLCAi4WiUCJVitVv4nAMBUuK+hKlxqxLbYNf+BMg8PD0VERCgtLc2+raioSGlpaYqMjHRhZQAAAKhq1/zIrSQlJSUpISFBbdu21e23366XXnpJp0+fVv/+/V1dGgAAAKqQKcLtgw8+qOPHj2vixInKzMxUmzZtlJqaWuJDZoCreXp6atKkSSWmxQDAtYr7Gqobi3G59RQAAACAa8Q1P+cWAAAAKEa4BQAAgGkQbgEAAGAahFsAAACYBuEWqCQbN25Ur169FBoaKovFohUrVlz2mE8++US33nqrPD09dcMNNyglJeWq1wkAFTV79mw1btxYtWrVUrt27bRly5ZLtl+6dKmaN2+uWrVqqVWrVvrvf/9bRZUChFug0pw+fVp/+tOfNHv27HK1P3jwoGJiYnT33Xdrx44dGjZsmB577DGtWbPmKlcKAOX3n//8R0lJSZo0aZK2b9+uP/3pT4qOjlZ2dnap7Tdt2qS+fftq4MCB+vrrrxUbG6vY2Fh9++23VVw5/qhYCgy4CiwWi5YvX67Y2Ngy24wZM0arVq1yuOH36dNHubm5Sk1NrYIqAeDy2rVrp9tuu02vvvqqpAvfAtqgQQM98cQTGjt2bIn2Dz74oE6fPq2VK1fat7Vv315t2rTRvHnzqqxu/HExcgu4SHp6uqKiohy2RUdHKz093UUVAYCjgoICbdu2zeFe5ebmpqioqDLvVdzb4GqEW8BFMjMzS3yLXlBQkGw2m3777TcXVQUA/3PixAkVFhaWeq/KzMws9Ziy7m1ltQcqG+EWAAAApkG4BVwkODhYWVlZDtuysrJktVrl5eXloqoA4H/q1asnd3f3Uu9VwcHBpR5T1r2trPZAZSPcAi4SGRmptLQ0h21r165VZGSkiyoCAEceHh6KiIhwuFcVFRUpLS2tzHsV9za4GuEWqCSnTp3Sjh07tGPHDkkXlvrasWOHMjIyJEnjxo1Tv3797O3/9re/6ccff9To0aO1b98+zZkzR0uWLNHw4cNdUT4AlCopKUlvvPGGFixYoL1792rw4ME6ffq0+vfvL0nq16+fxo0bZ28/dOhQpaamasaMGdq3b58mT56srVu3asiQIa7qAv5gari6AMAstm7dqrvvvtv+PCkpSZKUkJCglJQUHTt2zB50JSksLEyrVq3S8OHD9fLLL+v666/Xm2++qejo6CqvHQDK8uCDD+r48eOaOHGiMjMz1aZNG6Wmpto/NJaRkSE3t/+NlXXo0EGLFi3S+PHj9Y9//EPNmjXTihUrdPPNN7uqC/iDYZ1bAAAAmAbTEgAAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgEAAGAahFsAAACYBuEWAAAApkG4BQAAgGkQbgHgGmWxWLRixQpXlwEA1QrhFgCqqczMTD3xxBNq0qSJPD091aBBA/Xq1UtpaWmuLg0Aqq0ari4AAFDSoUOH1LFjRwUEBOj5559Xq1atdO7cOa1Zs0aJiYnat2+fq0sEgGqJkVsAqIb+/ve/y2KxaMuWLYqLi9ONN96oli1bKikpSV9++WWpx4wZM0Y33nijvL291aRJE02YMEHnzp2z79+5c6fuvvtu+fn5yWq1KiIiQlu3bpUk/fTTT+rVq5dq164tHx8ftWzZUv/973+rpK8AUJkYuQWAaiYnJ0epqal65pln5OPjU2J/QEBAqcf5+fkpJSVFoaGh2rVrlwYNGiQ/Pz+NHj1akhQfH69bbrlFc+fOlbu7u3bs2KGaNWtKkhITE1VQUKCNGzfKx8dHe/bska+v71XrIwBcLYRbAKhmvv/+exmGoebNm1fouPHjx9v/u3Hjxho5cqQWL15sD7cZGRkaNWqU/bzNmjWzt8/IyFBcXJxatWolSWrSpMmVdgMAXIJpCQBQzRiG4dRx//nPf9SxY0cFBwfL19dX48ePV0ZGhn1/UlKSHnvsMUVFRWnatGn64Ycf7PuefPJJPf300+rYsaMmTZqkb7755or7AQCuQLgFgGqmWbNmslgsFfrQWHp6uuLj49WjRw+tXLlSX3/9tf75z3+qoKDA3mby5MnavXu3YmJitH79eoWHh2v58uWSpMcee0w//vijHnnkEe3atUtt27bVK6+8Uul9A4CrzWI4O0QAALhqunfvrl27dmn//v0l5t3m5uYqICBAFotFy5cvV2xsrGbMmKE5c+Y4jMY+9thjeu+995Sbm1vqNfr27avTp0/rww8/LLFv3LhxWrVqFSO4AK45jNwCQDU0e/ZsFRYW6vbbb9f777+vAwcOaO/evZo1a5YiIyNLtG/WrJkyMjK0ePFi/fDDD5o1a5Z9VFaSfvvtNw0ZMkSffPKJfvrpJ33xxRf66quv1KJFC0nSsGHDtGbNGh08eFDbt2/Xhg0b7PsA4FrCB8oAoBpq0qSJtm/frmeeeUYjRozQsWPHVL9+fUVERGju3Lkl2v/5z3/W8OHDNWTIEOXn5ysmJkYTJkzQ5MmTJUnu7u765Zdf1K9fP2VlZalevXrq3bu3nnrqKUlSYWGhEhMTdeTIEVmtVnXr1k0zZ86syi4DQKVgWgIAAABMg2kJAAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADTINwCAADANAi3AAAAMA3CLQAAAEyDcAsAAADT+H+ci10wRpyccwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Counts:\n",
            "1.0    831\n",
            "0.0    509\n",
            "Name: TARGET_5Yrs, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "y.value_counts().plot(kind='bar')\n",
        "plt.title('Frequency of Each Class in Label Variable')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "plt.xticks(rotation=0)\n",
        "plt.show()\n",
        "\n",
        "\n",
        "class_counts = data[target_column].value_counts()\n",
        "print(\"Class Counts:\")\n",
        "print(class_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WW5CDFSOLCFd"
      },
      "source": [
        "#B. Verbally explain if balancing the label is required, why? (in 2-3 lines)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B1KVYl3LYTM"
      },
      "source": [
        "#Your answer here:\n",
        "balancing is required when there is a signifacent inbalance between the classes, if the classes are widely inbalanced the algorithem can perform poorly towards the minority class. in my case the inbalance isnt so severe hence no need for balancing.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46Pr9C1CLnlL"
      },
      "source": [
        "#C. If balancing is required, choose one over-sampling and one under-sampling balancing methods and perform them on your data.\n",
        "\n",
        "Verbally explain the logic behind the chosen balancing metohd, how does it work?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTtWHavyMF5S"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lc4fQg-tMVjJ"
      },
      "source": [
        "#Your answer here:\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROtq2k5CMeFK"
      },
      "source": [
        "#If balancing is not required, briefly explain why and choose one under-sampling method and one over-sampling method for balancing and perform them on your data.\n",
        "Additionally, verbally explain the logic behind the chosen balancing metohds, how does it work? (in 3 lines) answer:\n",
        "I explained above why balancing is not required, as for the logic i chose the majority stradegy so that the majority class will decrease to match the size of the minority class for complete balance and for the over sampling i chose 0.8 strategy so that the minority class will increase and be 80% of the majority class for a better balance between the classes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxOZYlYyLsON",
        "outputId": "0f515902-5d97-48ba-e0a6-4a93312858a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution before sampling:\n",
            "1.0    831\n",
            "0.0    509\n",
            "Name: TARGET_5Yrs, dtype: int64\n",
            "\n",
            "Class distribution after under-sampling:\n",
            "0.0    509\n",
            "1.0    509\n",
            "Name: TARGET_5Yrs, dtype: int64\n",
            "\n",
            "Class distribution after over-sampling:\n",
            "1.0    831\n",
            "0.0    664\n",
            "Name: TARGET_5Yrs, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "print(\"Class distribution before sampling:\")\n",
        "print(y.value_counts())\n",
        "\n",
        "\n",
        "chosen_under_sampler = RandomUnderSampler(sampling_strategy='majority')\n",
        "chosen_over_sampler = RandomOverSampler(sampling_strategy=0.8)\n",
        "\n",
        "\n",
        "X_resampled_under, y_resampled_under = chosen_under_sampler.fit_resample(X, y)\n",
        "X_resampled_over, y_resampled_over = chosen_over_sampler.fit_resample(X, y)\n",
        "\n",
        "\n",
        "print(\"\\nClass distribution after under-sampling:\")\n",
        "print(y_resampled_under.value_counts())\n",
        "\n",
        "print(\"\\nClass distribution after over-sampling:\")\n",
        "print(y_resampled_over.value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5BZb-AnDXnb"
      },
      "source": [
        "#4. Check for missing values:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glKyIdt4DcKz",
        "outputId": "8b77d9b9-9763-4f88-cdb5-eb14ca848e22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values:\n",
            "Name            0\n",
            "GP              0\n",
            "MIN             0\n",
            "PTS             0\n",
            "FGM             0\n",
            "FGA             0\n",
            "FG%             0\n",
            "3P Made         0\n",
            "3PA             0\n",
            "3P%            11\n",
            "FTM             0\n",
            "FTA             0\n",
            "FT%             0\n",
            "OREB            0\n",
            "DREB            0\n",
            "REB             0\n",
            "AST             0\n",
            "STL             0\n",
            "BLK             0\n",
            "TOV             0\n",
            "TARGET_5Yrs     0\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "\n",
        "missing_values = data.isnull().sum()\n",
        "print(\"Missing Values:\")\n",
        "print(missing_values)\n",
        "#there are no missing data the 0 in 3p% is data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYqhzgE8Dkdj"
      },
      "source": [
        "If there are no missing values in your data, follow the next steps:\n",
        "1. uncomment the following function by:\n",
        "\n",
        "  a. selecting all the code in the chunk\n",
        "\n",
        "  b. pressing \"ctrl\"+\"/\" to uncomment all lines\n",
        "2. assign the missing values-containing data to a new variable name (see example below).\n",
        "\n",
        "Say my dataset features is named X.\n",
        "\n",
        "Than the use of the function would be:\n",
        "\n",
        "\n",
        "```\n",
        "X_missing=add_missing_values(X)\n",
        " ```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l8vxkVPpDip8"
      },
      "outputs": [],
      "source": [
        "def add_missing_values(X_full):\n",
        "    import numpy as np\n",
        "    Col_names=X_full.columns\n",
        "    X_full=X_full.to_numpy()\n",
        "    rng = np.random.RandomState(4)\n",
        "    n_samples, n_features = X_full.shape\n",
        "\n",
        "    # Add missing values in 75% of the lines\n",
        "    missing_rate = 0.75\n",
        "    n_missing_samples = int(n_samples * missing_rate)\n",
        "\n",
        "    missing_samples = np.zeros(n_samples, dtype=bool)\n",
        "    missing_samples[:n_missing_samples] = True\n",
        "\n",
        "    rng.shuffle(missing_samples)\n",
        "    missing_features = rng.randint(0, n_features, n_missing_samples)\n",
        "    X_missing = X_full.copy()\n",
        "    X_missing[missing_samples, missing_features] = np.nan\n",
        "    X_missing=pd.DataFrame(X_missing)\n",
        "    X_missing.columns=Col_names\n",
        "    return X_missing\n",
        "# X_missing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZLGvx7YIUCc",
        "outputId": "7a031852-4497-4317-f853-490e8ea42028"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing Values:\n",
            "        GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  \\\n",
            "0     36.0  27.4  7.4  2.6  7.6  34.7      0.5  2.1  25.0  1.6  2.3  69.9   \n",
            "1     35.0  26.9  7.2  2.0  6.7  29.6      NaN  2.8  23.5  2.6  3.4  76.5   \n",
            "2     74.0  15.3  5.2  2.0  4.7  42.2      0.4  1.7  24.4  0.9  1.3   NaN   \n",
            "3     58.0  11.6  NaN  2.3  5.5  42.6      0.1  0.5  22.6  0.9  1.3  68.9   \n",
            "4     48.0  11.5  4.5  1.6  3.0  52.4      0.0  0.1   0.0  1.3  1.9  67.4   \n",
            "...    ...   ...  ...  ...  ...   ...      ...  ...   ...  ...  ...   ...   \n",
            "1335  80.0  15.8  4.3  1.6  3.6  43.3      0.0  0.2  14.3  1.2  1.5  79.2   \n",
            "1336  68.0  12.6  NaN  1.5  4.1  35.8      0.1  0.7  16.7  0.8  1.0  79.4   \n",
            "1337  43.0  12.1  5.4  2.2  3.9   NaN      0.0  0.0   0.0  1.0  1.6  64.3   \n",
            "1338  52.0  12.0  4.5  1.7  3.8  43.9      0.0  0.2  10.0  1.2  1.8  62.5   \n",
            "1339  47.0  11.7  4.4  1.6  4.4  36.9      0.4  1.3  33.3  0.7  1.0  67.3   \n",
            "\n",
            "      OREB  DREB  REB  AST  STL  BLK  TOV  \n",
            "0      0.7   3.4  NaN  1.9  0.4  0.4  1.3  \n",
            "1      0.5   2.0  2.4  3.7  1.1  0.5  1.6  \n",
            "2      0.5   1.7  2.2  1.0  0.5  0.3  1.0  \n",
            "3      1.0   0.9  1.9  0.8  0.6  0.1  1.0  \n",
            "4      NaN   1.5  2.5  0.3  0.3  0.4  0.8  \n",
            "...    ...   ...  ...  ...  ...  ...  ...  \n",
            "1335   0.4   0.8  1.2  2.5  NaN  0.2  0.8  \n",
            "1336   0.4   1.1  1.5  2.3  0.8  0.0  1.3  \n",
            "1337   1.5   2.3  3.8  0.3  0.3  0.4  0.9  \n",
            "1338   0.2   0.4  NaN  2.2  0.4  0.1  0.8  \n",
            "1339   0.2   0.7  0.9  1.4  0.7  0.1  0.9  \n",
            "\n",
            "[1340 rows x 19 columns]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_missing = add_missing_values(X)\n",
        "print(\"Missing Values:\")\n",
        "print(X_missing)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNhwID7JGHQz"
      },
      "source": [
        "\n",
        "#5. Impute the missing values using three different methods and assign the imputed output datasets into variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQDXRX4TIotK",
        "outputId": "a1aba053-8bac-4921-9eb9-862746430f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Imputed Values:\n",
            "     GP   MIN       PTS  FGM  FGA   FG%   3P Made  3PA   3P%  FTM  FTA  \\\n",
            "0  36.0  27.4  7.400000  2.6  7.6  34.7  0.500000  2.1  25.0  1.6  2.3   \n",
            "1  35.0  26.9  7.200000  2.0  6.7  29.6  0.248137  2.8  23.5  2.6  3.4   \n",
            "2  74.0  15.3  5.200000  2.0  4.7  42.2  0.400000  1.7  24.4  0.9  1.3   \n",
            "3  58.0  11.6  6.790532  2.3  5.5  42.6  0.100000  0.5  22.6  0.9  1.3   \n",
            "4  48.0  11.5  4.500000  1.6  3.0  52.4  0.000000  0.1   0.0  1.3  1.9   \n",
            "\n",
            "         FT%      OREB  DREB       REB  AST  STL  BLK  TOV  \n",
            "0  69.900000  0.700000   3.4  3.027132  1.9  0.4  0.4  1.3  \n",
            "1  76.500000  0.500000   2.0  2.400000  3.7  1.1  0.5  1.6  \n",
            "2  70.287731  0.500000   1.7  2.200000  1.0  0.5  0.3  1.0  \n",
            "3  68.900000  1.000000   0.9  1.900000  0.8  0.6  0.1  1.0  \n",
            "4  67.400000  1.009246   1.5  2.500000  0.3  0.3  0.4  0.8  \n",
            "\n",
            "Median Imputed Values:\n",
            "     GP   MIN  PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA   FT%  OREB  \\\n",
            "0  36.0  27.4  7.4  2.6  7.6  34.7      0.5  2.1  25.0  1.6  2.3  69.9   0.7   \n",
            "1  35.0  26.9  7.2  2.0  6.7  29.6      0.1  2.8  23.5  2.6  3.4  76.5   0.5   \n",
            "2  74.0  15.3  5.2  2.0  4.7  42.2      0.4  1.7  24.4  0.9  1.3  71.3   0.5   \n",
            "3  58.0  11.6  5.6  2.3  5.5  42.6      0.1  0.5  22.6  0.9  1.3  68.9   1.0   \n",
            "4  48.0  11.5  4.5  1.6  3.0  52.4      0.0  0.1   0.0  1.3  1.9  67.4   0.8   \n",
            "\n",
            "   DREB  REB  AST  STL  BLK  TOV  \n",
            "0   3.4  2.5  1.9  0.4  0.4  1.3  \n",
            "1   2.0  2.4  3.7  1.1  0.5  1.6  \n",
            "2   1.7  2.2  1.0  0.5  0.3  1.0  \n",
            "3   0.9  1.9  0.8  0.6  0.1  1.0  \n",
            "4   1.5  2.5  0.3  0.3  0.4  0.8  \n",
            "\n",
            "KNN Imputed Values:\n",
            "     GP   MIN   PTS  FGM  FGA   FG%  3P Made  3PA   3P%  FTM  FTA    FT%  \\\n",
            "0  36.0  27.4  7.40  2.6  7.6  34.7     0.50  2.1  25.0  1.6  2.3  69.90   \n",
            "1  35.0  26.9  7.20  2.0  6.7  29.6     0.42  2.8  23.5  2.6  3.4  76.50   \n",
            "2  74.0  15.3  5.20  2.0  4.7  42.2     0.40  1.7  24.4  0.9  1.3  76.16   \n",
            "3  58.0  11.6  4.06  2.3  5.5  42.6     0.10  0.5  22.6  0.9  1.3  68.90   \n",
            "4  48.0  11.5  4.50  1.6  3.0  52.4     0.00  0.1   0.0  1.3  1.9  67.40   \n",
            "\n",
            "   OREB  DREB  REB  AST  STL  BLK  TOV  \n",
            "0  0.70   3.4  3.0  1.9  0.4  0.4  1.3  \n",
            "1  0.50   2.0  2.4  3.7  1.1  0.5  1.6  \n",
            "2  0.50   1.7  2.2  1.0  0.5  0.3  1.0  \n",
            "3  1.00   0.9  1.9  0.8  0.6  0.1  1.0  \n",
            "4  1.02   1.5  2.5  0.3  0.3  0.4  0.8  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "mean_imputer = SimpleImputer(strategy='mean')\n",
        "X_mean_imputed = mean_imputer.fit_transform(X_missing)\n",
        "\n",
        "\n",
        "median_imputer = SimpleImputer(strategy='median')\n",
        "X_median_imputed = median_imputer.fit_transform(X_missing)\n",
        "\n",
        "\n",
        "knn_imputer = KNNImputer(n_neighbors=5)\n",
        "X_knn_imputed = knn_imputer.fit_transform(X_missing)\n",
        "\n",
        "# Convert the imputed arrays back to DataFrames\n",
        "X_mean_imputed_df = pd.DataFrame(X_mean_imputed,columns= X.columns)\n",
        "X_median_imputed_df = pd.DataFrame(X_median_imputed, columns= X.columns)\n",
        "X_knn_imputed_df = pd.DataFrame(X_knn_imputed, columns= X.columns)\n",
        "\n",
        "\n",
        "print(\"Mean Imputed Values:\")\n",
        "print(X_mean_imputed_df.head())\n",
        "\n",
        "print(\"\\nMedian Imputed Values:\")\n",
        "print(X_median_imputed_df.head())\n",
        "\n",
        "print(\"\\nKNN Imputed Values:\")\n",
        "print(X_knn_imputed_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdbJRpF8IsY8"
      },
      "source": [
        "#6. Preprocessing (for both imputed datasets):\n",
        "standardize or normalize the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzahU-AlJV3c"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "scaler_mean = StandardScaler()\n",
        "X_mean_imputed_scaled = scaler_mean.fit_transform(X_mean_imputed_df)\n",
        "\n",
        "scaler_median = StandardScaler()\n",
        "X_median_imputed_scaled = scaler_median.fit_transform(X_median_imputed_df)\n",
        "\n",
        "scaler_knn = StandardScaler()\n",
        "X_knn_imputed_scaled = scaler_knn.fit_transform(X_knn_imputed_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pg_K-4_gNjbb"
      },
      "source": [
        "#7. Train test split:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Uobk5J_Nl5j"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "X_train_mean, X_test_mean, y_train_mean, y_test_mean = train_test_split(\n",
        "    X_mean_imputed_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train_median, X_test_median, y_train_median, y_test_median = train_test_split(\n",
        "    X_median_imputed_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "X_train_knn, X_test_knn, y_train_knn, y_test_knn = train_test_split(\n",
        "    X_knn_imputed_scaled, y, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p32CMu4SNEQb"
      },
      "source": [
        "#8. Training models (for both imputed datasets):\n",
        "**a.** choose **three** classification algorithms, one must be either random forest or XGBoost or catboost,another must be an algorithm that **wasn't** discussed in class and apply the algorithms on the train set.  \n",
        "\n",
        "**b.** apply hyperparameter tuning on  two out of three algorithms using gridsearchCV function.\n",
        "\n",
        "Apply a pipeline to the learning process of one of the algorithms, pipeing must include:\n",
        "\n",
        "\n",
        "*   imputation\n",
        "*   standardization or normalization\n",
        "*   chossing the learning algorithm and a dictionary for the hyperparameter search.\n",
        "\n",
        "##In this part you should create 9 learning models: 3 imputed dataframes * 3 algorithms\n",
        "\n",
        "**c.** print the best hyperparameters for both models.\n",
        "reminder, if the tuned model is named \"grid\" than to get the best hyperparameter combination use the following function:\n",
        "\n",
        "\n",
        "```\n",
        "grid.best_params_\n",
        "```\n",
        "\n",
        "\n",
        "**d.** Veraverbally explain: what is the role of the chosen hyperparmeters in the learning algorithms? Explain how the unlearned algorithm that you chose works. (in 3-4 lines)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WLveUiA9Y7Iz",
        "outputId": "d6d51e68-5e3e-4c59-d909-eec3b3446529"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RandomForest Best Hyperparameters:\n",
            "{'max_depth': 10, 'n_estimators': 200}\n",
            "GradientBoosting Best Hyperparameters:\n",
            "{'learning_rate': 0.1, 'n_estimators': 50}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "random_forest_classifier = RandomForestClassifier(random_state=42)\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "gradient_boosting_classifier = GradientBoostingClassifier(random_state=42)\n",
        "\n",
        "# Train the classifiers on the training data\n",
        "random_forest_classifier.fit(X_train_mean, y_train_mean)\n",
        "random_forest_classifier.fit(X_train_median, y_train_median)\n",
        "random_forest_classifier.fit(X_train_knn, y_train_knn)\n",
        "\n",
        "knn_classifier.fit(X_train_mean, y_train_mean)\n",
        "knn_classifier.fit(X_train_median, y_train_median)\n",
        "knn_classifier.fit(X_train_knn, y_train_knn)\n",
        "\n",
        "\n",
        "gradient_boosting_classifier.fit(X_train_mean, y_train_mean)\n",
        "gradient_boosting_classifier.fit(X_train_median, y_train_median)\n",
        "gradient_boosting_classifier.fit(X_train_knn, y_train_knn)\n",
        "\n",
        "\n",
        "# Hyperparameter tuning using GridSearchCV for RandomForest and GradientBoosting\n",
        "param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20]}\n",
        "grid_search_rf = GridSearchCV(random_forest_classifier, param_grid_rf, cv=5)\n",
        "grid_search_rf.fit(X_train_mean, y_train_mean)\n",
        "grid_search_rf.fit(X_train_median, y_train_median)\n",
        "grid_search_rf.fit(X_train_knn, y_train_knn)\n",
        "\n",
        "param_grid_gb = {'n_estimators': [50, 100, 200], 'learning_rate': [0.1, 0.01, 0.001]}\n",
        "grid_search_gb = GridSearchCV(gradient_boosting_classifier, param_grid_gb, cv=5)\n",
        "grid_search_gb.fit(X_train_mean, y_train_mean)\n",
        "grid_search_gb.fit(X_train_median, y_train_median)\n",
        "grid_search_gb.fit(X_train_knn, y_train_knn)\n",
        "\n",
        "# Creating a pipeline for k-Nearest Neighbors\n",
        "knn_pipeline = Pipeline([\n",
        "    ('imputer', SimpleImputer()),\n",
        "    ('scaler', MinMaxScaler()),\n",
        "    ('knn', KNeighborsClassifier())\n",
        "])\n",
        "\n",
        "print(\"RandomForest Best Hyperparameters:\")\n",
        "print(grid_search_rf.best_params_)\n",
        "\n",
        "\n",
        "print(\"GradientBoosting Best Hyperparameters:\")\n",
        "print(grid_search_gb.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySInCwHzY6kG"
      },
      "source": [
        "#Your answer here:\n",
        "\n",
        "the role of hyperparmeters are to influence how the algorithm learns and generalizes from the data.  in RandomForest and GradientBoosting, the n_estimators hyperparameter defines the number of decision trees to be created. max_depth controls the depth of these trees.\n",
        "learning_rate controls the step size at which the algorithm adjusts its predictions based on the error from the previous models.\n",
        "\n",
        "unlearned algorithm - Gradient Boosting works by iteratively training weak models, each focused on correcting the errors of the previous model, using gradients of the loss function to guide adjustments, and combining their predictions with scaled weights to form a strong predictive model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXR9AHo9Y3gJ"
      },
      "source": [
        "#9. A. Predict the y variable on both the train set and the test set (for both imputed datasets and for both algorithms - 18 predictions in total):\n",
        "3 imputed datasets * 3 classification algorithms * (train+test)\n",
        "\n",
        "and create and print a summrizing table of the accuracy, recall, precision and f1-score of each prediction.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OGXWpYFLZyHh",
        "outputId": "abb6613b-0542-40cf-b000-632da4fb6fdd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   imputed_dataset                                   classifier    set  \\\n",
            "0             mean      RandomForestClassifier(random_state=42)  Train   \n",
            "1             mean      RandomForestClassifier(random_state=42)   Test   \n",
            "2             mean                       KNeighborsClassifier()  Train   \n",
            "3             mean                       KNeighborsClassifier()   Test   \n",
            "4             mean  GradientBoostingClassifier(random_state=42)  Train   \n",
            "5             mean  GradientBoostingClassifier(random_state=42)   Test   \n",
            "6           median      RandomForestClassifier(random_state=42)  Train   \n",
            "7           median      RandomForestClassifier(random_state=42)   Test   \n",
            "8           median                       KNeighborsClassifier()  Train   \n",
            "9           median                       KNeighborsClassifier()   Test   \n",
            "10          median  GradientBoostingClassifier(random_state=42)  Train   \n",
            "11          median  GradientBoostingClassifier(random_state=42)   Test   \n",
            "12             knn      RandomForestClassifier(random_state=42)  Train   \n",
            "13             knn      RandomForestClassifier(random_state=42)   Test   \n",
            "14             knn                       KNeighborsClassifier()  Train   \n",
            "15             knn                       KNeighborsClassifier()   Test   \n",
            "16             knn  GradientBoostingClassifier(random_state=42)  Train   \n",
            "17             knn  GradientBoostingClassifier(random_state=42)   Test   \n",
            "\n",
            "    accuracy    recall  precision  f1_score  \n",
            "0   0.998134  0.998489   0.998489  0.998489  \n",
            "1   0.705224  0.828402   0.736842  0.779944  \n",
            "2   0.765858  0.848943   0.788219  0.817455  \n",
            "3   0.682836  0.781065   0.733333  0.756447  \n",
            "4   0.870336  0.948640   0.856753  0.900358  \n",
            "5   0.723881  0.834320   0.754011  0.792135  \n",
            "6   0.998134  1.000000   0.996988  0.998492  \n",
            "7   0.731343  0.840237   0.759358  0.797753  \n",
            "8   0.763993  0.841390   0.790071  0.814923  \n",
            "9   0.708955  0.828402   0.740741  0.782123  \n",
            "10  0.856343  0.938066   0.846049  0.889685  \n",
            "11  0.731343  0.828402   0.765027  0.795455  \n",
            "12  0.996269  0.998489   0.995482  0.996983  \n",
            "13  0.712687  0.834320   0.742105  0.785515  \n",
            "14  0.763993  0.838369   0.791726  0.814380  \n",
            "15  0.679104  0.804734   0.719577  0.759777  \n",
            "16  0.866604  0.938066   0.858921  0.896751  \n",
            "17  0.716418  0.834320   0.746032  0.787709  \n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "imputed_datasets = ['mean', 'median', 'knn']\n",
        "classifiers = [random_forest_classifier, knn_classifier, gradient_boosting_classifier]\n",
        "\n",
        "results = {'imputed_dataset': [], 'classifier': [], 'set': [], 'accuracy': [], 'recall': [], 'precision': [], 'f1_score': []}\n",
        "\n",
        "\n",
        "for imputed_data in imputed_datasets:\n",
        "    for clf in classifiers:\n",
        "        if imputed_data == 'mean':\n",
        "            X_train = X_train_mean\n",
        "            X_test = X_test_mean\n",
        "            y_train = y_train_mean\n",
        "            y_test = y_test_mean\n",
        "        elif imputed_data == 'median':\n",
        "            X_train = X_train_median\n",
        "            X_test = X_test_median\n",
        "            y_train = y_train_median\n",
        "            y_test = y_test_median\n",
        "        elif imputed_data == 'knn':\n",
        "            X_train = X_train_knn\n",
        "            X_test = X_test_knn\n",
        "            y_train = y_train_knn\n",
        "            y_test = y_test_knn\n",
        "\n",
        "        # Fit the classifier on the train data\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on train and test data\n",
        "        y_pred_train = clf.predict(X_train)\n",
        "        y_pred_test = clf.predict(X_test)\n",
        "\n",
        "        # Calculate evaluation metrics for train and test sets\n",
        "        accuracy_train = accuracy_score(y_train, y_pred_train)\n",
        "        recall_train = recall_score(y_train, y_pred_train)\n",
        "        precision_train = precision_score(y_train, y_pred_train)\n",
        "        f1_train = f1_score(y_train, y_pred_train)\n",
        "\n",
        "        accuracy_test = accuracy_score(y_test, y_pred_test)\n",
        "        recall_test = recall_score(y_test, y_pred_test)\n",
        "        precision_test = precision_score(y_test, y_pred_test)\n",
        "        f1_test = f1_score(y_test, y_pred_test)\n",
        "\n",
        "        # Store the results in the dictionary\n",
        "        results['imputed_dataset'].append(imputed_data)\n",
        "        results['classifier'].append(str(clf))\n",
        "        results['set'].append('Train')\n",
        "        results['accuracy'].append(accuracy_train)\n",
        "        results['recall'].append(recall_train)\n",
        "        results['precision'].append(precision_train)\n",
        "        results['f1_score'].append(f1_train)\n",
        "\n",
        "        results['imputed_dataset'].append(imputed_data)\n",
        "        results['classifier'].append(str(clf))\n",
        "        results['set'].append('Test')\n",
        "        results['accuracy'].append(accuracy_test)\n",
        "        results['recall'].append(recall_test)\n",
        "        results['precision'].append(precision_test)\n",
        "        results['f1_score'].append(f1_test)\n",
        "\n",
        "\n",
        "summary_table = pd.DataFrame(results)\n",
        "\n",
        "\n",
        "print(summary_table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q70fd0FZzqS"
      },
      "source": [
        "#B. Verbally explain which model resulted with the best outcome with consideration to over-fitting, under-fitting and proper-fitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8EIHUuGa5Cu"
      },
      "source": [
        "#Your answer here:\n",
        "the data shows that gradient boosting and and random forest perform the best, perhaps one is slightly better than the other but they both suffer from over fitting since the training accuracy is significantly higher than the test. the KNN does not perform as well as the other 2 but exhibits relatively better performance in terms of avoiding overfitting, as the gap between training and testing accuracy is smaller.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjsR7CqOaRnC"
      },
      "source": [
        "#C. Print the classification_report of both the trainset and the test set using the best model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqPM-0PVa1Ab",
        "outputId": "a672de8f-7962-4d21-829a-01861bbc112f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for Training Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00       410\n",
            "         1.0       1.00      1.00      1.00       662\n",
            "\n",
            "    accuracy                           1.00      1072\n",
            "   macro avg       1.00      1.00      1.00      1072\n",
            "weighted avg       1.00      1.00      1.00      1072\n",
            "\n",
            "\n",
            "Classification Report for Testing Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.66      0.55      0.60        99\n",
            "         1.0       0.76      0.83      0.79       169\n",
            "\n",
            "    accuracy                           0.73       268\n",
            "   macro avg       0.71      0.69      0.70       268\n",
            "weighted avg       0.72      0.73      0.72       268\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "best_model = RandomForestClassifier()\n",
        "\n",
        "\n",
        "best_model.fit(X_train_mean, y_train_mean)\n",
        "\n",
        "\n",
        "y_pred_train = best_model.predict(X_train_mean)\n",
        "y_pred_test = best_model.predict(X_test_mean)\n",
        "\n",
        "\n",
        "print(\"Classification Report for Training Set:\")\n",
        "print(classification_report(y_train_mean, y_pred_train))\n",
        "\n",
        "\n",
        "print(\"\\nClassification Report for Testing Set:\")\n",
        "print(classification_report(y_test_mean, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0JUvoRmObuf"
      },
      "source": [
        "#D. Verbally explain 2 more quality measures of your choice. explain: is the score good? what is the meaning of each measure?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyUVqCG6a5mq"
      },
      "source": [
        "#Your answer here:\n",
        "Precision - measures the accuracy of positive predictions made by the model, it focuses on the portion of the predicted positive instances that are actually correct.\n",
        "Recall - measures the ability of the model to correctly identify all positive instances in the dataset, it focuses on the portion of actual positive instances that were correctly identified by the model.\n",
        "\n",
        "in the training set the scores were good both 0 and 1 were 100% accurate, in the testing set the scores were not as good.. the prediction for 0 were bad across all metrics but the prediction for 1 was better.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M573muOoa6Kp"
      },
      "source": [
        "#Good Luck!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}